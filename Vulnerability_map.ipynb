{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "34557c4129972600f46ab73f6d60d31e0ec191e7d378fd14c15cd532233346ff"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing requried libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from xgboost.sklearn import XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2539, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#Importing files\n",
    "Train = pd.read_csv('Vulnerality map/Train_maskedv2.csv')\n",
    "Test = pd.read_csv('Vulnerality map/Test_maskedv2.csv')\n",
    "# Spliting the Training Dataset\n",
    "TrTrain, Trtest = train_test_split(Train, test_size = 0.2, random_state = 101)\n",
    "Train = TrTrain.copy()\n",
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Train.drop(['target_pct_vunerable', 'ward'], axis =1)\n",
    "Y = Train['target_pct_vunerable']\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# feat = SelectKBest(score_func=f_regression, k='all')\n",
    "# Selectd_X = feat.fit(X, Y)\n",
    "# FeatScores = pd.DataFrame({'Features': X.columns, 'Score':Selectd_X.scores_})\n",
    "# print(FeatScores.nlargest(X.shape[1],'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Standardization\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lasso: 7.719686 (0.622986)\n",
      "ElsN: 7.585099 (0.635491)\n",
      "sgd: 6.780366 (0.697048)\n",
      "Ridge: 6.644756 (0.709048)\n",
      "LR: 6.710905 (0.707087)\n",
      "knr: 5.689822 (0.704597)\n",
      "rfr: 2.348607 (0.762410)\n",
      "xg: 4.508830 (0.753241)\n"
     ]
    }
   ],
   "source": [
    "# Finding the BaseLine perfomance of the various models\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "\n",
    "# Adding algorthms\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('ElsN', ElasticNet()))\n",
    "models.append(('sgd', SGDRegressor()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('knr', KNeighborsRegressor()))\n",
    "models.append(('rfr', RandomForestRegressor()))\n",
    "models.append(('xg', XGBRegressor(objective ='reg:squarederror')))\n",
    "# evaluate -cross validation- each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring =['neg_root_mean_squared_error', 'r2']\n",
    "for name, model in models:\n",
    "\tkfold = KFold(n_splits=10, random_state=7)\n",
    "\tcv_results = cross_validate(model, X, Y, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, -cv_results['train_neg_root_mean_squared_error'].mean(), cv_results['test_r2'].mean())\n",
    "\tprint(msg)\n"
   ]
  },
  {
   "source": [
    "# Importing libraries for bayesian optimization on Xgboost\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_space = {'objective': ['reg:squarederror'], 'colsample_bytree':Real(0.1, 1.0), \"learning_rate\": Real(0.01, 0.1), \"max_depth\": Integer(2, 20), \"alpha\": Integer(2, 20), 'n_estimators': Integer(100, 500),'nthread': Integer(1, 20) }\n",
    " \n",
    "xb_bayes = BayesSearchCV(XGBRegressor(), search_space, n_iter=32, scoring='r2', n_jobs=-1, cv =10)\n",
    "xb_bayes.fit(X, Y)\n",
    "print(xb_bayes.best_score_)\n",
    "print(xb_bayes.best_estimator_)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# importing libraries for bayesian optimization on Random Forest\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_space = {'max_depth': Integer(10, 100), 'n_estimators':Integer(200,500), \"max_features\": Categorical(['auto', 'sqrt','log2']), \"min_samples_leaf\": Integer(2, 10), \"min_samples_split\": Integer(2, 10)}\n",
    "\n",
    "rfr_bayes = BayesSearchCV(RandomForestRegressor(), search_space, n_iter=32, scoring='r2', n_jobs=-1, cv =10)\n",
    "rfr_bayes.fit(X, Y)\n",
    "print(rfr_bayes.best_score_)\n",
    "print(rfr_bayes.best_estimator_)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Creating an ensemble and run on train data\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "vt = VotingRegressor([('rfr',RandomForestRegressor(max_depth=99, max_features='sqrt', min_samples_leaf=2, n_estimators=447)),\n",
    "                    ('xg', XGBRegressor(alpha=8, colsample_bytree=0.4799197099139273, learning_rate=0.044338376966254166, max_depth=7, n_estimators=315, nthread=16, objective='reg:squarederror'))])\n",
    "scoring = ['neg_root_mean_squared_error', 'r2']\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "cv_results = cross_validate(vt, X, Y, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "print( \"%s: %f (%f)\" % ('vt', -cv_results['train_neg_root_mean_squared_error'].mean(), cv_results['test_r2'].mean()))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vt: 1.677818 (0.775563)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "model = Pipeline([('sc', StandardScaler()), ('vt', VotingRegressor([('rfr',RandomForestRegressor(max_depth=99, max_features='sqrt', min_samples_leaf=2, n_estimators=447)),\n",
    "                    ('xg', XGBRegressor(alpha=8, colsample_bytree=0.4799197099139273, learning_rate=0.044338376966254166, max_depth=7, n_estimators=315, nthread=16, objective='reg:squarederror'))]))])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('rs', RobustScaler()), ('vt', VotingRegressor([('rfr',RandomForestRegressor(max_depth=99, max_features='sqrt', min_samples_leaf=2, n_estimators=447)),\n",
    "                    ('xg', XGBRegressor(alpha=8, colsample_bytree=0.4799197099139273, learning_rate=0.044338376966254166, max_depth=7, n_estimators=315, nthread=16, objective='reg:squarederror'))]))])"
   ]
  },
  {
   "source": [
    "model.fit(TrTrain.drop(['target_pct_vunerable', 'ward'], axis = 1), TrTrain['target_pct_vunerable'])\n",
    "y_pred= model.predict(Test.drop('ward', axis=1))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": []
  },
  {
   "source": [
    "one = pd.DataFrame(Test['ward'])\n",
    "two = pd.DataFrame(y_pred)\n",
    "Done = pd.concat([one,two], axis=1)\n",
    "Done.columns = ['ward','target_pct_vunerable']\n",
    "Done.to_csv('Vmap-Solution.csv',index=False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "# SECOND EXPERIMENT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Train.drop(['target_pct_vunerable', 'ward'], axis =1)\n",
    "Y = Train['target_pct_vunerable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2539"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=.98, svd_solver='auto')\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lasso: 8.485372 (0.546417)\n",
      "ElsN: 8.643186 (0.531027)\n",
      "sgd: 7.022862 (0.672244)\n",
      "Ridge: 6.999707 (0.676000)\n",
      "LR: 6.999706 (0.675991)\n",
      "knr: 6.137412 (0.652441)\n",
      "rfr: 2.491717 (0.737810)\n",
      "xg: 5.210281 (0.725122)\n"
     ]
    }
   ],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "\n",
    "# Adding algorthms\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('ElsN', ElasticNet()))\n",
    "models.append(('sgd', SGDRegressor()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('knr', KNeighborsRegressor()))\n",
    "models.append(('rfr', RandomForestRegressor()))\n",
    "models.append(('xg', XGBRegressor(objective ='reg:squarederror')))\n",
    "# evaluate -cross validation- each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring =['neg_root_mean_squared_error', 'r2']\n",
    "for name, model in models:\n",
    "\tkfold = KFold(n_splits=10, random_state=7)\n",
    "\tcv_results = cross_validate(model, X, Y, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, -cv_results['train_neg_root_mean_squared_error'].mean(), cv_results['test_r2'].mean())\n",
    "\tprint(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for bayesian optimization on Xgboost\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_space = {'objective': ['reg:squarederror'], 'colsample_bytree':Real(0.1, 1.0), \"learning_rate\": Real(0.01, 0.1), \"max_depth\": Integer(2, 20), \"alpha\": Integer(2, 20), 'n_estimators': Integer(100, 500),'nthread': Integer(1, 20) }\n",
    " \n",
    "xb_bayes = BayesSearchCV(XGBRegressor(), search_space, n_iter=32, scoring='r2', n_jobs=-1, cv =10)\n",
    "xb_bayes.fit(X, Y)\n",
    "print(xb_bayes.best_score_)\n",
    "print(xb_bayes.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ensemble and run on train data\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "vt = VotingRegressor([('rfr',RandomForestRegressor(max_depth=99, max_features='sqrt', min_samples_leaf=2, n_estimators=447)),\n",
    "                    ('xg', XGBRegressor(alpha=8, colsample_bytree=0.4799197099139273, learning_rate=0.044338376966254166, max_depth=7, n_estimators=315, nthread=16, objective='reg:squarederror'))])\n",
    "scoring = ['neg_root_mean_squared_error', 'r2']\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "cv_results = cross_validate(vt, X, Y, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "print( \"%s: %f (%f)\" % ('vt', -cv_results['train_neg_root_mean_squared_error'].mean(), cv_results['test_r2'].mean()))"
   ]
  },
  {
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "md = Sequential()\n",
    "md.add(Dense(32, activation= 'relu', input_dim = train_X.shape[1]))\n",
    "md.add(Dense(units = 32, activation= 'relu'))\n",
    "md.add(Dense(units = 32, activation= 'relu'))\n",
    "md.add(Dense(units = 1))\n",
    "\n",
    "md.compile(optimizer='adam', loss= 'mean_squared_error')\n",
    "md.fit(train_X, train_y, batch_size=10, epochs=50, verbose=0)\n",
    "ypred = md.predict(test_X)\n",
    "print('rmse:',round(mse(test_y, ypred)**(1/2),3))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}